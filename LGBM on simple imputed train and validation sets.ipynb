{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb75546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7528e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training sets\n",
    "train_median=pd.read_csv('Training data(median).csv')\n",
    "train_mean=pd.read_csv('Training data(mean).csv')\n",
    "train_condmean=pd.read_csv('Training data(conditional mean).csv')\n",
    "train_condmedian=pd.read_csv('Training data(conditional median).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cc48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_median=pd.read_csv('Validation set(median).csv')\n",
    "valid_mean=pd.read_csv('Validation set(mean).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb68f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beae273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm=LGBMClassifier(is_unbalance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7983ac52",
   "metadata": {},
   "source": [
    "Converting categorical columns to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aed2a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_condmedian.select_dtypes('object'):\n",
    "    train_condmedian[i]=train_condmedian[i].astype('category')\n",
    "train_condmedian['Term']=train_condmedian['Term'].astype('category')\n",
    "train_condmedian['Tax Liens']=train_condmedian['Tax Liens'].astype('category')\n",
    "train_condmedian['Bankruptcies']=train_condmedian['Bankruptcies'].astype('category')\n",
    "train_condmedian['Number of Credit Problems']=train_condmedian['Number of Credit Problems'].astype('category')\n",
    "train_condmedian['Years in current job']=train_condmedian['Years in current job'].astype('category')\n",
    "train_condmedian['Number of Credit Problems']=train_condmedian['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accb8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_condmean.select_dtypes('object'):\n",
    "    train_condmean[i]=train_condmean[i].astype('category')\n",
    "train_condmean['Term']=train_condmean['Term'].astype('category')\n",
    "train_condmean['Tax Liens']=train_condmean['Tax Liens'].astype('category')\n",
    "train_condmean['Bankruptcies']=train_condmean['Bankruptcies'].astype('category')\n",
    "train_condmean['Number of Credit Problems']=train_condmean['Number of Credit Problems'].astype('category')\n",
    "train_condmean['Years in current job']=train_condmean['Years in current job'].astype('category')\n",
    "train_condmean['Number of Credit Problems']=train_condmean['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fc5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_median.select_dtypes('object'):\n",
    "    train_median[i]=train_median[i].astype('category')\n",
    "train_median['Term']=train_median['Term'].astype('category')\n",
    "train_median['Tax Liens']=train_median['Tax Liens'].astype('category')\n",
    "train_median['Bankruptcies']=train_median['Bankruptcies'].astype('category')\n",
    "train_median['Number of Credit Problems']=train_median['Number of Credit Problems'].astype('category')\n",
    "train_median['Years in current job']=train_median['Years in current job'].astype('category')\n",
    "train_median['Number of Credit Problems']=train_median['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15bab35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_mean.select_dtypes('object'):\n",
    "    train_mean[i]=train_mean[i].astype('category')\n",
    "train_mean['Term']=train_mean['Term'].astype('category')\n",
    "train_mean['Tax Liens']=train_mean['Tax Liens'].astype('category')\n",
    "train_mean['Bankruptcies']=train_mean['Bankruptcies'].astype('category')\n",
    "train_mean['Number of Credit Problems']=train_mean['Number of Credit Problems'].astype('category')\n",
    "train_mean['Years in current job']=train_mean['Years in current job'].astype('category')\n",
    "train_mean['Number of Credit Problems']=train_mean['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2cadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_median.select_dtypes('object'):\n",
    "    valid_median[i]=valid_median[i].astype('category')\n",
    "valid_median['Term']=valid_median['Term'].astype('category')\n",
    "valid_median['Tax Liens']=valid_median['Tax Liens'].astype('category')\n",
    "valid_median['Bankruptcies']=valid_median['Bankruptcies'].astype('category')\n",
    "valid_median['Number of Credit Problems']=valid_median['Number of Credit Problems'].astype('category')\n",
    "valid_median['Years in current job']=valid_median['Years in current job'].astype('category')\n",
    "valid_median['Number of Credit Problems']=valid_median['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a4337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_mean.select_dtypes('object'):\n",
    "    valid_mean[i]=valid_mean[i].astype('category')\n",
    "valid_mean['Term']=valid_mean['Term'].astype('category')\n",
    "valid_mean['Tax Liens']=valid_mean['Tax Liens'].astype('category')\n",
    "valid_mean['Bankruptcies']=valid_mean['Bankruptcies'].astype('category')\n",
    "valid_mean['Number of Credit Problems']=valid_mean['Number of Credit Problems'].astype('category')\n",
    "valid_mean['Years in current job']=valid_mean['Years in current job'].astype('category')\n",
    "valid_mean['Number of Credit Problems']=valid_mean['Number of Credit Problems'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07271462",
   "metadata": {},
   "source": [
    "On conditional median set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e746961",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainmed=train_condmedian.drop('Loan Status',axis=1)\n",
    "y_trainmed=train_condmedian['Loan Status']\n",
    "x_validmed=valid_median.drop('Loan Status',axis=1)\n",
    "y_validmed=valid_median['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8acee318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_trainmed,y_trainmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b45962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.686987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.216882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.402210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.578254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.281806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.686987\n",
       "recall         0.216882\n",
       "precision      0.402210\n",
       "roc_auc_score  0.578254\n",
       "f1_score       0.281806"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_validmed,lgbm.predict(x_validmed)), recall_score(y_validmed,lgbm.predict(x_validmed)),\n",
    "                   precision_score(y_validmed,lgbm.predict(x_validmed)), roc_auc_score(y_validmed,lgbm.predict_proba(x_validmed)[:,1]),\n",
    "                   f1_score(y_validmed,lgbm.predict(x_validmed))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02eec577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.922590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.930430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.984562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.871894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.922590\n",
       "recall         0.930430\n",
       "precision      0.820287\n",
       "roc_auc_score  0.984562\n",
       "f1_score       0.871894"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_trainmed,lgbm.predict(x_trainmed)), recall_score(y_trainmed,lgbm.predict(x_trainmed)),\n",
    "                   precision_score(y_trainmed,lgbm.predict(x_trainmed)), roc_auc_score(y_trainmed,lgbm.predict_proba(x_trainmed)[:,1]),\n",
    "                   f1_score(y_trainmed,lgbm.predict(x_trainmed))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ee52c",
   "metadata": {},
   "source": [
    "On conditional mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a119d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainme=train_condmean.drop('Loan Status',axis=1)\n",
    "y_trainme=train_condmean['Loan Status']\n",
    "x_validme=valid_mean.drop('Loan Status',axis=1)\n",
    "y_validme=valid_mean['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266efebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_trainme,y_trainme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c94d2dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.931883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.936389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.841042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.988220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.886158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.931883\n",
       "recall         0.936389\n",
       "precision      0.841042\n",
       "roc_auc_score  0.988220\n",
       "f1_score       0.886158"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_trainme,lgbm.predict(x_trainme)), recall_score(y_trainme,lgbm.predict(x_trainme)),\n",
    "                   precision_score(y_trainme,lgbm.predict(x_trainme)), roc_auc_score(y_trainme,lgbm.predict_proba(x_trainme)[:,1]),\n",
    "                   f1_score(y_trainme,lgbm.predict(x_trainme))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cdeb5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.676864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.314598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.408353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.638716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.355396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.676864\n",
       "recall         0.314598\n",
       "precision      0.408353\n",
       "roc_auc_score  0.638716\n",
       "f1_score       0.355396"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_validme,lgbm.predict(x_validme)), recall_score(y_validme,lgbm.predict(x_validme)),\n",
    "                   precision_score(y_validme,lgbm.predict(x_validme)), roc_auc_score(y_validme,lgbm.predict_proba(x_validme)[:,1]),\n",
    "                   f1_score(y_validme,lgbm.predict(x_validme))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de25ba5",
   "metadata": {},
   "source": [
    "On Median set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58c4ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainmed1=train_median.drop('Loan Status',axis=1)\n",
    "y_trainmed1=train_median['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815fee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_trainmed1,y_trainmed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea9ca9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.730458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.758417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.516329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.830461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.614385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.730458\n",
       "recall         0.758417\n",
       "precision      0.516329\n",
       "roc_auc_score  0.830461\n",
       "f1_score       0.614385"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_trainmed1,lgbm.predict(x_trainmed1)), recall_score(y_trainmed1,lgbm.predict(x_trainmed1)),\n",
    "                   precision_score(y_trainmed1,lgbm.predict(x_trainmed1)), roc_auc_score(y_trainmed1,lgbm.predict_proba(x_trainmed1)[:,1]),\n",
    "                   f1_score(y_trainmed1,lgbm.predict(x_trainmed1))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8e60cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.578169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.795432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.382302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.707067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.516408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.578169\n",
       "recall         0.795432\n",
       "precision      0.382302\n",
       "roc_auc_score  0.707067\n",
       "f1_score       0.516408"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_validmed,lgbm.predict(x_validmed)), recall_score(y_validmed,lgbm.predict(x_validmed)),\n",
    "                   precision_score(y_validmed,lgbm.predict(x_validmed)), roc_auc_score(y_validmed,lgbm.predict_proba(x_validmed)[:,1]),\n",
    "                   f1_score(y_validmed,lgbm.predict(x_validmed))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3b65b",
   "metadata": {},
   "source": [
    "On Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e9ffb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainme1=train_mean.drop('Loan Status',axis=1)\n",
    "y_trainme1=train_mean['Loan Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bada3f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(is_unbalance=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(x_trainme1,y_trainme1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4d3b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.734943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.755835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.522036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.835851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.617547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.734943\n",
       "recall         0.755835\n",
       "precision      0.522036\n",
       "roc_auc_score  0.835851\n",
       "f1_score       0.617547"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_trainme1,lgbm.predict(x_trainme1)), recall_score(y_trainme1,lgbm.predict(x_trainme1)),\n",
    "                   precision_score(y_trainme1,lgbm.predict(x_trainme1)), roc_auc_score(y_trainme1,lgbm.predict_proba(x_trainme1)[:,1]),\n",
    "                   f1_score(y_trainme1,lgbm.predict(x_trainme1))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9598592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.590935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.791063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.390299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.711504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.522703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "accuracy       0.590935\n",
       "recall         0.791063\n",
       "precision      0.390299\n",
       "roc_auc_score  0.711504\n",
       "f1_score       0.522703"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using metrics to test the model\n",
    "from sklearn.metrics import *\n",
    "pd.DataFrame(data=[accuracy_score(y_validme,lgbm.predict(x_validme)), recall_score(y_validme,lgbm.predict(x_validme)),\n",
    "                   precision_score(y_validme,lgbm.predict(x_validme)), roc_auc_score(y_validme,lgbm.predict_proba(x_validme)[:,1]),\n",
    "                   f1_score(y_validme,lgbm.predict(x_validme))], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec262a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
